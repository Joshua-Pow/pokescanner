{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PokeScanner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshua-Pow/pokescanner/blob/main/PokeScanner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Importing libraries / Data Loading and Splitting\n",
        "\n"
      ],
      "metadata": {
        "id": "-sqsjspqPsY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "use_cuda = True\n",
        "\n",
        "torch.manual_seed(1) # set the random seed\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) #Must have folder inside drive called PokeScanner\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    # you can add other transformations in this list\n",
        "    transforms.Resize(250),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "Ws6j7ioiPpHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24da3d6-3bbe-4d89-efa1-6cb77fe341de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = '/content/gdrive/MyDrive/PokeScanner' #Everyone has had this folder shared with them, Right click the folder and click \"Add shortcut to Drive\"\n",
        "train_set = datasets.ImageFolder(filePath+'/training', transform=transform) #NEED TO SPLIT DATA\n",
        "validation_set = datasets.ImageFolder(filePath+'/validation', transform=transform)\n",
        "testing_set = datasets.ImageFolder(filePath+'/testing', transform=transform)\n",
        "\n",
        "print('Number of Images:', len(train_set))"
      ],
      "metadata": {
        "id": "h6983FGSY0n9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ee35f5-656d-4125-b03c-0bc91f73847f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images: 6820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Model Building and Sanity Checking\n",
        "\n",
        "Build a convolutional neural network model that takes the (224x224 RGB) image as input, and predicts the pokemon"
      ],
      "metadata": {
        "id": "BTGSzk07P2m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PokemonClassifier(nn.Module):\n",
        "      def __init__(self, kernel_size):\n",
        "          super(PokemonClassifier, self).__init__()\n",
        "          self.conv1 = nn.Conv2d(3, 2, kernel_size) #in_channels, out_chanels, kernel_size\n",
        "          self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride \n",
        "          self.conv2 = nn.Conv2d(2, 2, kernel_size) #in_channels, out_chanels, kernel_size\n",
        "          self.fc1 = nn.Linear(5618, 32) #needs input-dependent value\n",
        "          self.fc2 = nn.Linear(32, 9)\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = self.pool(F.relu(self.conv1(x)))\n",
        "          x = self.pool(F.relu(self.conv2(x)))\n",
        "          x = x.view(-1, 5618)\n",
        "          x = F.relu(self.fc1(x))\n",
        "          x = self.fc2(x)\n",
        "          return x"
      ],
      "metadata": {
        "id": "j8v_N94OP1LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From tut3a\n",
        "def get_accuracy(model, accuracy_data, batch_size):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in torch.utils.data.DataLoader(accuracy_data, batch_size=batch_size):\n",
        "        \n",
        "        \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        else:\n",
        "          print(\"get_accuracy: no cuda\")\n",
        "        #############################################\n",
        "        \n",
        "        \n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "W4tMq-H09Tpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From tut3a\n",
        "def train(model, data, size, num_epochs, learning_rate):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=size, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    iters, losses, train_acc, val_acc, epochList = [], [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "\n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            else:\n",
        "              print(\"Train: no cuda\")\n",
        "            #############################################\n",
        "              \n",
        "            out = model(imgs)             # forward pass\n",
        "\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/size)             # compute *average* loss\n",
        "            n += 1\n",
        "        train_acc.append(get_accuracy(model, accuracy_data=train_set, batch_size=size)) # compute training accuracy \n",
        "        val_acc.append(get_accuracy(model, accuracy_data=validation_set, batch_size=size))  # compute validation accuracy\n",
        "        epochList.append(epoch)\n",
        "        print(\"Epoch {}: Training Accuracy: {} Validation Accuracy: {}\".format(epoch, train_acc[epoch], val_acc[epoch]))\n",
        "    \n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochList, train_acc, label=\"Train\")\n",
        "    plt.plot(epochList, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "  \n"
      ],
      "metadata": {
        "id": "sorZBi_L9SdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PokemonClassifier()\n",
        "\n",
        "#proper model\n",
        "#############################################\n",
        "#To Enable GPU Usage\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "  print(\"cuda\")\n",
        "#############################################\n",
        "\n",
        "#Basic first attempt at training\n",
        "train(model, train_set, size=64, num_epochs=10, learning_rate=0.001)"
      ],
      "metadata": {
        "id": "9WDrZfbl9Yai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVN2VKOY1Bjh"
      },
      "outputs": [],
      "source": [
        "#Hello World\n",
        "#Test Line"
      ]
    }
  ]
}